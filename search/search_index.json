{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"mahsm Documentation","text":"<p>Build production-grade AI systems with declarative simplicity.</p> <p>mahsm is a Python framework that combines the best tools for building, tracing, and evaluating LLM-powered applications\u2014wrapped in a simple, declarative API.</p>"},{"location":"#what-is-mahsm","title":"What is mahsm?","text":"<p>mahsm integrates four powerful frameworks into a unified development experience:</p> <ul> <li>DSPy \u2192 Prompt engineering through programming</li> <li>LangGraph \u2192 Stateful, cyclical agent workflows  </li> <li>Langfuse \u2192 Production-grade observability</li> <li>EvalProtocol \u2192 Systematic evaluation &amp; testing</li> </ul> <p>Instead of learning four different APIs, you learn one: mahsm's declarative interface.</p>"},{"location":"#why-mahsm","title":"Why mahsm?","text":""},{"location":"#the-problem","title":"The Problem","text":"<p>Building production LLM applications requires: 1. Smart prompting (DSPy's modules &amp; optimizers) 2. Complex workflows (LangGraph's state machines) 3. Deep observability (Langfuse's tracing) 4. Rigorous testing (EvalProtocol's evaluations)</p> <p>Each framework has its own API, patterns, and integration challenges.</p>"},{"location":"#the-solution","title":"The Solution","text":"<p>mahsm provides:</p> <pre><code>import mahsm as ma\nimport dspy\nimport os\n\n# 1. Configure once\nlm = dspy.LM('openai/gpt-4o-mini', api_key=os.getenv(\"OPENAI_API_KEY\"))\ndspy.configure(lm=lm)\nma.tracing.init()  # Automatic tracing for everything\n\n# 2. Define agents declaratively\n@ma.dspy_node\nclass Researcher(ma.Module):\n    def __init__(self):\n        super().__init__()\n        self.researcher = dspy.ChainOfThought(\"question -&gt; findings\")\n\n    def forward(self, question):\n        return self.researcher(question=question)\n\n# 3. Build workflows visually\nworkflow = ma.graph.StateGraph(MyState)\nworkflow.add_node(\"research\", Researcher())\nworkflow.add_edge(ma.START, \"research\")\ngraph = workflow.compile()\n\n# 4. Run &amp; automatically trace\nresult = graph.invoke({\"question\": \"...\"})\n# \u2705 All LLM calls traced to Langfuse\n# \u2705 Full execution graph visible\n# \u2705 Costs &amp; latencies tracked\n\n# 5. Evaluate systematically\n@ma.testing.evaluation_test(...)\nasync def test_quality(row):\n    return await ma.testing.aha_judge(row, rubric=\"...\")\n# \u2705 Results synced to Langfuse\n# \u2705 Model comparisons automated\n</code></pre> <p>Result: You write less code, iterate faster, and ship with confidence.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#declarative-api","title":"\ud83c\udfaf Declarative API","text":"<p>Define what you want, not how to build it:</p> <pre><code># Instead of manually chaining prompts...\n@ma.dspy_node\nclass MyAgent(ma.Module):\n    def __init__(self):\n        super().__init__()\n        self.predictor = dspy.ChainOfThought(\"input -&gt; output\")\n</code></pre>"},{"location":"#automatic-tracing","title":"\ud83d\udd04 Automatic Tracing","text":"<p>One line enables observability for all frameworks:</p> <pre><code>ma.tracing.init()\n# \u2705 DSPy modules traced\n# \u2705 LangGraph nodes traced\n# \u2705 Custom @observe functions traced\n</code></pre>"},{"location":"#unified-testing","title":"\ud83d\udcca Unified Testing","text":"<p>Test across models, prompts, and configurations:</p> <pre><code>@ma.testing.evaluation_test(\n    completion_params=[\n        {\"model\": \"openai/gpt-4o-mini\"},\n        {\"model\": \"openai/gpt-4o\"},\n    ]\n)\nasync def test_agent(row):\n    # Runs on both models, compares results\n    pass\n</code></pre>"},{"location":"#production-ready","title":"\ud83d\ude80 Production-Ready","text":"<ul> <li>Type-safe state management (TypedDict)</li> <li>Structured logging with Langfuse</li> <li>Automated evaluation pipelines</li> <li>Cost &amp; latency tracking</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>pip install mahsm\n</code></pre>"},{"location":"#your-first-agent-60-seconds","title":"Your First Agent (60 seconds)","text":"<pre><code>import mahsm as ma\nfrom typing import TypedDict\nimport dspy\nimport os\n\n# Configure\nlm = dspy.LM('openai/gpt-4o-mini', api_key=os.getenv(\"OPENAI_API_KEY\"))\ndspy.configure(lm=lm)\nma.tracing.init()\n\n# Define state\nclass State(TypedDict):\n    question: str\n    answer: str\n\n# Define agent\n@ma.dspy_node\nclass QA(ma.Module):\n    def __init__(self):\n        super().__init__()\n        self.qa = dspy.ChainOfThought(\"question -&gt; answer\")\n\n    def forward(self, question):\n        return self.qa(question=question)\n\n# Build graph\nworkflow = ma.graph.StateGraph(State)\nworkflow.add_node(\"qa\", QA())\nworkflow.add_edge(ma.START, \"qa\")\nworkflow.add_edge(\"qa\", ma.END)\ngraph = workflow.compile()\n\n# Run\nresult = graph.invoke({\"question\": \"What is DSPy?\"})\nprint(result[\"answer\"])\n# Output visible in Langfuse UI automatically!\n</code></pre> <p>Next: Follow the Quick Start Guide for a complete walkthrough.</p>"},{"location":"#learning-path","title":"Learning Path","text":""},{"location":"#new-to-llm-development","title":"\ud83c\udf93 New to LLM Development?","text":"<p>Start here to learn the fundamentals:</p> <ol> <li>Installation - Set up your environment</li> <li>Core Concepts - Understanding the mahsm philosophy</li> <li>Your First Agent - Build a complete agent step-by-step</li> </ol>"},{"location":"#want-to-understand-the-building-blocks","title":"\ud83d\udd27 Want to Understand the Building Blocks?","text":"<p>Deep dive into each framework:</p> <ul> <li>DSPy Basics - Signatures, modules, optimizers</li> <li>LangGraph Basics - State, nodes, edges, routing</li> <li>Langfuse Basics - Tracing, observability, scoring</li> <li>EvalProtocol Basics - Testing, evaluation, metrics</li> </ul>"},{"location":"#ready-to-build","title":"\ud83d\ude80 Ready to Build?","text":"<p>Check out complete examples:</p> <ul> <li>Research Agent - Multi-step reasoning pipeline</li> <li>Multi-Agent System - Coordinated agent teams</li> <li>Evaluation Pipeline - Comprehensive testing setup</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>mahsm is built on four pillars:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             Your Application                \u2502\n\u2502   (Agents, Workflows, Evaluations)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u2502 mahsm API\n                  \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              mahsm Core                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502  @dspy   \u2502 .tracing \u2502   .testing   \u2502    \u2502\n\u2502  \u2502  _node   \u2502  .init() \u2502 .evaluation  \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502           \u2502            \u2502\n   \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502  DSPy   \u2502 \u2502Langfuse \u2502 \u2502EvalProtocol \u2502\n   \u2502 Modules \u2502 \u2502 Tracing \u2502 \u2502    Tests    \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502           \u2502            \u2502\n   \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502        LangGraph Workflows          \u2502\n   \u2502   (StateGraph, compile, invoke)     \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key Points: - DSPy powers intelligent prompting - LangGraph orchestrates execution - Langfuse traces everything automatically - EvalProtocol validates quality</p> <p>mahsm's <code>@dspy_node</code> decorator bridges DSPy modules and LangGraph nodes, while <code>ma.tracing.init()</code> instruments the entire stack.</p>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>\ud83d\udcd6 Documentation: You're reading it! Explore the sidebar \u2192</li> <li>\ud83d\udcac GitHub Discussions: Ask questions</li> <li>\ud83d\udc1b Issues: Report bugs</li> <li>\u2b50 Star the repo: Show your support</li> </ul>"},{"location":"#whats-next","title":"What's Next?","text":"<ul> <li>Installation Guide \u2192 Set up mahsm</li> <li>Quick Start \u2192 Build your first agent  </li> <li>DSPy Overview \u2192 Learn prompt engineering</li> <li>LangGraph Overview \u2192 Learn workflows</li> </ul> <p>Ready to build? Let's go! \ud83d\ude80</p>"},{"location":"building-blocks/dspy/overview/","title":"DSPy Overview","text":"<p>TL;DR: DSPy turns prompt engineering into programming\u2014define what you want, not how to prompt for it.</p>"},{"location":"building-blocks/dspy/overview/#what-is-dspy","title":"What is DSPy?","text":"<p>DSPy (Declarative Self-improving Language Programs in Python) is a framework for building LLM applications through programming, not manual prompting.</p> <p>Instead of writing and tweaking prompts like this:</p> <pre><code># \u274c Traditional prompting\nprompt = \"\"\"\nYou are a helpful assistant. Given a question, provide a detailed answer.\n\nQuestion: {question}\nThink step by step and provide your reasoning.\n\nAnswer:\n\"\"\"\nresponse = llm.complete(prompt.format(question=\"What is DSPy?\"))\n</code></pre> <p>You write code like this:</p> <pre><code># \u2705 DSPy approach\nimport dspy\n\nclass QA(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.cot = dspy.ChainOfThought(\"question -&gt; answer\")\n\n    def forward(self, question):\n        return self.cot(question=question)\n\nqa = QA()\nresult = qa(question=\"What is DSPy?\")\nprint(result.answer)\n</code></pre> <p>Key Insight: You declare the structure (chain-of-thought reasoning), and DSPy generates the actual prompts automatically.</p>"},{"location":"building-blocks/dspy/overview/#why-dspy","title":"Why DSPy?","text":""},{"location":"building-blocks/dspy/overview/#1-composability","title":"1. Composability","text":"<p>Build complex pipelines from simple components:</p> <pre><code>class ResearchPipeline(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.generate_query = dspy.ChainOfThought(\"question -&gt; search_query\")\n        self.synthesize = dspy.ChainOfThought(\"question, context -&gt; answer\")\n\n    def forward(self, question):\n        # Step 1: Generate search query\n        query_result = self.generate_query(question=question)\n\n        # Step 2: Search (simulated)\n        context = search_api(query_result.search_query)\n\n        # Step 3: Synthesize answer\n        return self.synthesize(question=question, context=context)\n</code></pre>"},{"location":"building-blocks/dspy/overview/#2-automatic-optimization","title":"2. Automatic Optimization","text":"<p>DSPy can automatically improve your prompts:</p> <pre><code>from dspy.teleprompt import BootstrapFewShot\n\n# Define success metric\ndef validate_answer(example, prediction):\n    return example.answer.lower() in prediction.answer.lower()\n\n# Optimize the pipeline\noptimizer = BootstrapFewShot(metric=validate_answer)\noptimized_qa = optimizer.compile(QA(), trainset=examples)\n\n# optimized_qa now has better prompts learned from examples!\n</code></pre>"},{"location":"building-blocks/dspy/overview/#3-model-agnostic","title":"3. Model Agnostic","text":"<p>Switch between models without changing code:</p> <pre><code># Use GPT-4o-mini\nlm = dspy.LM('openai/gpt-4o-mini', api_key=os.getenv(\"OPENAI_API_KEY\"))\ndspy.configure(lm=lm)\n\n# Later, switch to Claude\nlm = dspy.LM('anthropic/claude-3-5-sonnet-20241022', api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\ndspy.configure(lm=lm)\n# Your code stays the same!\n</code></pre>"},{"location":"building-blocks/dspy/overview/#core-concepts","title":"Core Concepts","text":""},{"location":"building-blocks/dspy/overview/#1-signatures","title":"1. Signatures","text":"<p>Signatures define input \u2192 output specifications:</p> <pre><code># Simple signature\n\"question -&gt; answer\"\n\n# Multi-input signature\n\"question, context -&gt; answer\"\n\n# With hints\n\"question -&gt; answer: a detailed, technical response\"\n</code></pre> <p>Learn more about Signatures \u2192</p>"},{"location":"building-blocks/dspy/overview/#2-modules","title":"2. Modules","text":"<p>Modules are reusable components that use signatures:</p> <pre><code># Built-in modules\ndspy.Predict(\"question -&gt; answer\")          # Basic prediction\ndspy.ChainOfThought(\"question -&gt; answer\")   # With reasoning\ndspy.ReAct(\"question -&gt; answer\")            # Tool-using agent\n\n# Custom modules\nclass MyAgent(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.predictor = dspy.ChainOfThought(\"input -&gt; output\")\n\n    def forward(self, input):\n        return self.predictor(input=input)\n</code></pre> <p>Learn more about Modules \u2192</p>"},{"location":"building-blocks/dspy/overview/#3-optimizers-teleprompts","title":"3. Optimizers (Teleprompts)","text":"<p>Optimizers automatically improve your modules:</p> <pre><code>from dspy.teleprompt import BootstrapFewShot, MIPRO\n\n# Few-shot learning\noptimizer = BootstrapFewShot(metric=my_metric)\noptimized = optimizer.compile(my_module, trainset=data)\n\n# Advanced optimization\noptimizer = MIPRO(metric=my_metric)\noptimized = optimizer.compile(my_module, trainset=train, valset=val)\n</code></pre> <p>Learn more about Optimizers \u2192</p>"},{"location":"building-blocks/dspy/overview/#dspy-in-mahsm","title":"DSPy in mahsm","text":"<p>mahsm makes DSPy even easier by integrating it with LangGraph workflows:</p>"},{"location":"building-blocks/dspy/overview/#the-dspy_node-decorator","title":"The <code>@dspy_node</code> Decorator","text":"<p>Convert any DSPy module into a LangGraph node:</p> <pre><code>import mahsm as ma\n\n@ma.dspy_node\nclass Researcher(ma.Module):\n    def __init__(self):\n        super().__init__()\n        self.research = dspy.ChainOfThought(\"question -&gt; findings\")\n\n    def forward(self, question):\n        return self.research(question=question)\n\n# Use it in a workflow\nworkflow = ma.graph.StateGraph(MyState)\nworkflow.add_node(\"researcher\", Researcher())  # \u2705 Works seamlessly\n</code></pre> <p>How it works: 1. <code>@dspy_node</code> wraps your DSPy module 2. Automatically extracts inputs from state 3. Merges outputs back into state 4. Handles Langfuse tracing</p> <p>Learn more about @dspy_node \u2192</p>"},{"location":"building-blocks/dspy/overview/#quick-example-building-a-qa-agent","title":"Quick Example: Building a Q&amp;A Agent","text":"<p>Let's build a complete Q&amp;A agent using DSPy + mahsm:</p> <pre><code>import mahsm as ma\nfrom typing import TypedDict\nimport dspy\nimport os\n\n# 1. Configure DSPy\nlm = dspy.LM('openai/gpt-4o-mini', api_key=os.getenv(\"OPENAI_API_KEY\"))\ndspy.configure(lm=lm)\nma.tracing.init()\n\n# 2. Define state\nclass QAState(TypedDict):\n    question: str\n    reasoning: str\n    answer: str\n\n# 3. Create DSPy module\n@ma.dspy_node\nclass QAAgent(ma.Module):\n    def __init__(self):\n        super().__init__()\n        self.qa = dspy.ChainOfThought(\"question -&gt; reasoning, answer\")\n\n    def forward(self, question):\n        return self.qa(question=question)\n\n# 4. Build LangGraph workflow\nworkflow = ma.graph.StateGraph(QAState)\nworkflow.add_node(\"qa\", QAAgent())\nworkflow.add_edge(ma.START, \"qa\")\nworkflow.add_edge(\"qa\", ma.END)\ngraph = workflow.compile()\n\n# 5. Run\nresult = graph.invoke({\"question\": \"What are the benefits of using DSPy?\"})\nprint(f\"Answer: {result['answer']}\")\nprint(f\"Reasoning: {result['reasoning']}\")\n# \u2705 Automatically traced in Langfuse!\n</code></pre>"},{"location":"building-blocks/dspy/overview/#when-to-use-dspy","title":"When to Use DSPy","text":""},{"location":"building-blocks/dspy/overview/#great-for","title":"\u2705 Great For:","text":"<ul> <li>Complex reasoning tasks requiring chain-of-thought</li> <li>Multi-step pipelines with intermediate outputs</li> <li>Optimizable systems where you can measure success</li> <li>Model-agnostic applications that need portability</li> </ul>"},{"location":"building-blocks/dspy/overview/#not-ideal-for","title":"\u274c Not Ideal For:","text":"<ul> <li>Simple one-shot prompts (just use the LLM API directly)</li> <li>When you need exact prompt control (DSPy generates prompts)</li> <li>Streaming responses with partial updates (DSPy is batch-oriented)</li> </ul>"},{"location":"building-blocks/dspy/overview/#common-patterns","title":"Common Patterns","text":""},{"location":"building-blocks/dspy/overview/#1-sequential-processing","title":"1. Sequential Processing","text":"<pre><code>class Pipeline(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.step1 = dspy.ChainOfThought(\"input -&gt; intermediate\")\n        self.step2 = dspy.ChainOfThought(\"intermediate -&gt; output\")\n\n    def forward(self, input):\n        intermediate = self.step1(input=input)\n        return self.step2(intermediate=intermediate.intermediate)\n</code></pre>"},{"location":"building-blocks/dspy/overview/#2-conditional-logic","title":"2. Conditional Logic","text":"<pre><code>class ConditionalAgent(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.classifier = dspy.Predict(\"question -&gt; category\")\n        self.tech_expert = dspy.ChainOfThought(\"question -&gt; answer\")\n        self.general_expert = dspy.Predict(\"question -&gt; answer\")\n\n    def forward(self, question):\n        category = self.classifier(question=question).category\n\n        if \"technical\" in category.lower():\n            return self.tech_expert(question=question)\n        else:\n            return self.general_expert(question=question)\n</code></pre>"},{"location":"building-blocks/dspy/overview/#3-tool-use-with-react","title":"3. Tool Use with ReAct","text":"<pre><code>class ToolUser(dspy.Module):\n    def __init__(self, tools):\n        super().__init__()\n        self.react = dspy.ReAct(\"question -&gt; answer\")\n        self.react.tools = tools\n\n    def forward(self, question):\n        return self.react(question=question)\n</code></pre>"},{"location":"building-blocks/dspy/overview/#next-steps","title":"Next Steps","text":"<ul> <li>DSPy Signatures \u2192 Learn how to define inputs and outputs</li> <li>DSPy Modules \u2192 Explore built-in modules like ChainOfThought, ReAct</li> <li>DSPy Optimizers \u2192 Automatically improve your prompts</li> <li>Best Practices \u2192 Tips for production DSPy code</li> </ul>"},{"location":"building-blocks/dspy/overview/#external-resources","title":"External Resources","text":"<ul> <li>Official DSPy Docs - Comprehensive DSPy documentation</li> <li>DSPy GitHub - Source code and examples</li> <li>DSPy Paper - Research paper explaining DSPy</li> </ul> <p>Ready to dive deeper? Start with Signatures \u2192</p>"},{"location":"building-blocks/dspy/signatures/","title":"DSPy Signatures","text":"<p>TL;DR: Signatures are type specifications that tell DSPy what inputs your module needs and what outputs it should produce.</p>"},{"location":"building-blocks/dspy/signatures/#what-is-a-signature","title":"What is a Signature?","text":"<p>A signature in DSPy is like a function type hint\u2014it specifies: - What inputs the module receives - What outputs it should produce - Optional descriptions for each field</p> <p>Think of it as a contract between your code and the LLM.</p>"},{"location":"building-blocks/dspy/signatures/#basic-syntax","title":"Basic Syntax","text":""},{"location":"building-blocks/dspy/signatures/#string-signatures","title":"String Signatures","text":"<p>The simplest way to define a signature:</p> <pre><code>import dspy\n\n# Single input \u2192 single output\n\"question -&gt; answer\"\n\n# Multiple inputs \u2192 single output\n\"question, context -&gt; answer\"\n\n# Multiple inputs \u2192 multiple outputs\n\"question, context -&gt; answer, confidence\"\n</code></pre> <p>Format: <code>input1, input2 -&gt; output1, output2</code></p>"},{"location":"building-blocks/dspy/signatures/#example","title":"Example","text":"<pre><code># Create a predictor with a signature\nqa = dspy.ChainOfThought(\"question -&gt; answer\")\n\n# Use it\nresult = qa(question=\"What is DSPy?\")\nprint(result.answer)  # Access output by name\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#adding-descriptions","title":"Adding Descriptions","text":"<p>You can add hints to guide the LLM:</p> <pre><code># Add output description\n\"question -&gt; answer: a concise, factual response\"\n\n# Add input descriptions\n\"question: a technical question -&gt; answer: a detailed explanation\"\n\n# Multiple fields with descriptions\n\"question: user query, context: relevant docs -&gt; answer: synthesized response, sources: list of citations\"\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#example-with-descriptions","title":"Example with Descriptions","text":"<pre><code>predictor = dspy.ChainOfThought(\n    \"question: a user's question about AI -&gt; answer: a detailed, technical explanation\"\n)\n\nresult = predictor(question=\"How does attention work in transformers?\")\nprint(result.answer)\n# Output will be more detailed and technical due to the hint\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#class-based-signatures","title":"Class-Based Signatures","text":"<p>For complex signatures, use classes:</p> <pre><code>import dspy\n\nclass QASignature(dspy.Signature):\n    \"\"\"Answer questions with detailed explanations.\"\"\"\n\n    question = dspy.InputField(desc=\"The user's question\")\n    context = dspy.InputField(desc=\"Relevant background information\")\n    answer = dspy.OutputField(desc=\"A comprehensive answer\")\n    confidence = dspy.OutputField(desc=\"Confidence score (0-100)\")\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#using-class-signatures","title":"Using Class Signatures","text":"<pre><code># Pass the class (not an instance!)\npredictor = dspy.ChainOfThought(QASignature)\n\nresult = predictor(\n    question=\"What is DSPy?\",\n    context=\"DSPy is a framework for prompt programming...\"\n)\nprint(result.answer)\nprint(result.confidence)\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#input-and-output-fields","title":"Input and Output Fields","text":""},{"location":"building-blocks/dspy/signatures/#inputfield","title":"InputField","text":"<p>Defines what the module receives:</p> <pre><code>import dspy\n\nclass MySignature(dspy.Signature):\n    # Basic input\n    query = dspy.InputField()\n\n    # With description\n    context = dspy.InputField(desc=\"Background information\")\n\n    # With format hint\n    examples = dspy.InputField(desc=\"Few-shot examples\", format=list)\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#outputfield","title":"OutputField","text":"<p>Defines what the module produces:</p> <pre><code>class MySignature(dspy.Signature):\n    # Basic output\n    answer = dspy.OutputField()\n\n    # With description\n    reasoning = dspy.OutputField(desc=\"Step-by-step thought process\")\n\n    # With prefix (shown before the output in the prompt)\n    summary = dspy.OutputField(prefix=\"SUMMARY:\")\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#common-patterns","title":"Common Patterns","text":""},{"location":"building-blocks/dspy/signatures/#1-simple-qa","title":"1. Simple Q&amp;A","text":"<pre><code>\"question -&gt; answer\"\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#2-context-aware-qa","title":"2. Context-Aware Q&amp;A","text":"<pre><code>\"question, context -&gt; answer\"\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#3-multi-output","title":"3. Multi-Output","text":"<pre><code>\"document -&gt; summary, key_points, sentiment\"\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#4-complex-reasoning","title":"4. Complex Reasoning","text":"<pre><code>class ReasoningSignature(dspy.Signature):\n    \"\"\"Solve complex problems with step-by-step reasoning.\"\"\"\n\n    problem = dspy.InputField(desc=\"The problem to solve\")\n    constraints = dspy.InputField(desc=\"Any constraints or requirements\")\n\n    reasoning = dspy.OutputField(desc=\"Step-by-step thought process\")\n    solution = dspy.OutputField(desc=\"The final solution\")\n    confidence = dspy.OutputField(desc=\"Confidence level (low/medium/high)\")\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#5-classification","title":"5. Classification","text":"<pre><code>class ClassificationSignature(dspy.Signature):\n    \"\"\"Classify text into categories.\"\"\"\n\n    text = dspy.InputField(desc=\"The text to classify\")\n    categories = dspy.InputField(desc=\"Valid categories (comma-separated)\")\n\n    category = dspy.OutputField(desc=\"The chosen category\")\n    reason = dspy.OutputField(desc=\"Brief explanation for the choice\")\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#signatures-in-mahsm","title":"Signatures in mahsm","text":"<p>When using <code>@dspy_node</code>, signatures determine how inputs are extracted from state:</p> <pre><code>import mahsm as ma\nfrom typing import TypedDict\n\n# 1. Define state\nclass ResearchState(TypedDict):\n    question: str\n    context: str\n    answer: str\n    reasoning: str\n\n# 2. Create module with signature\n@ma.dspy_node\nclass Researcher(ma.Module):\n    def __init__(self):\n        super().__init__()\n        # Signature matches state fields\n        self.research = dspy.ChainOfThought(\"question, context -&gt; answer, reasoning\")\n\n    def forward(self, question, context):\n        return self.research(question=question, context=context)\n\n# 3. Use in workflow\nworkflow = ma.graph.StateGraph(ResearchState)\nworkflow.add_node(\"researcher\", Researcher())\n\n# When the node runs:\n# - \"question\" and \"context\" are extracted from state\n# - \"answer\" and \"reasoning\" are written back to state\n</code></pre> <p>Key Point: Match your signature field names to your state keys for seamless integration!</p>"},{"location":"building-blocks/dspy/signatures/#advanced-dynamic-signatures","title":"Advanced: Dynamic Signatures","text":"<p>Create signatures programmatically:</p> <pre><code>def create_signature(input_fields, output_fields):\n    inputs = \", \".join(input_fields)\n    outputs = \", \".join(output_fields)\n    return f\"{inputs} -&gt; {outputs}\"\n\n# Example: Dynamic fields\nsig = create_signature([\"question\", \"context\"], [\"answer\", \"score\"])\n# Result: \"question, context -&gt; answer, score\"\n\npredictor = dspy.Predict(sig)\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#best-practices","title":"Best Practices","text":""},{"location":"building-blocks/dspy/signatures/#do","title":"\u2705 Do:","text":"<ol> <li> <p>Use descriptive field names <pre><code>\"user_question -&gt; detailed_answer\"  # \u2705 Clear\n</code></pre></p> </li> <li> <p>Add descriptions for ambiguous fields <pre><code>\"query: the user's search query -&gt; results: list of relevant items\"\n</code></pre></p> </li> <li> <p>Match state keys in mahsm <pre><code>class State(TypedDict):\n    question: str\n    answer: str\n\n# Signature matches state\ndspy.ChainOfThought(\"question -&gt; answer\")\n</code></pre></p> </li> <li> <p>Use multi-output for intermediate reasoning <pre><code>\"question -&gt; reasoning, answer\"  # \u2705 Captures thought process\n</code></pre></p> </li> </ol>"},{"location":"building-blocks/dspy/signatures/#dont","title":"\u274c Don't:","text":"<ol> <li> <p>Use vague names <pre><code>\"input -&gt; output\"  # \u274c Not descriptive\n</code></pre></p> </li> <li> <p>Mix concerns in one field <pre><code>\"query -&gt; answer_and_confidence\"  # \u274c Split into two outputs\n</code></pre></p> </li> <li> <p>Over-complicate <pre><code># \u274c Too many fields\n\"q, c1, c2, c3, c4 -&gt; a, r1, r2, r3, conf, meta\"\n</code></pre></p> </li> </ol>"},{"location":"building-blocks/dspy/signatures/#troubleshooting","title":"Troubleshooting","text":""},{"location":"building-blocks/dspy/signatures/#issue-llm-not-returning-expected-output","title":"Issue: LLM not returning expected output","text":"<p>Solution: Add more specific descriptions</p> <pre><code># Before (vague)\n\"text -&gt; category\"\n\n# After (specific)\n\"text: a customer review -&gt; category: one of [positive, negative, neutral]\"\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#issue-output-format-is-inconsistent","title":"Issue: Output format is inconsistent","text":"<p>Solution: Use structured output hints</p> <pre><code>class StructuredSignature(dspy.Signature):\n    query = dspy.InputField()\n    answer = dspy.OutputField(desc=\"Answer in JSON format with keys: summary, details\")\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#issue-state-keys-dont-match-signature","title":"Issue: State keys don't match signature","text":"<p>Solution: Ensure field names align</p> <pre><code># State has \"user_query\"\nclass State(TypedDict):\n    user_query: str\n\n# \u274c Signature uses \"question\"\ndspy.ChainOfThought(\"question -&gt; answer\")  # Won't find \"question\" in state!\n\n# \u2705 Match the key\ndspy.ChainOfThought(\"user_query -&gt; answer\")\n</code></pre>"},{"location":"building-blocks/dspy/signatures/#next-steps","title":"Next Steps","text":"<ul> <li>DSPy Modules \u2192 Learn about Predict, ChainOfThought, ReAct</li> <li>Your First Agent \u2192 Build a complete agent</li> <li>API Reference: @dspy_node \u2192 mahsm integration details</li> </ul>"},{"location":"building-blocks/dspy/signatures/#external-resources","title":"External Resources","text":"<ul> <li>DSPy Signatures Documentation - Official guide</li> <li>DSPy Examples - Real-world signature usage</li> </ul> <p>Next: Explore DSPy Modules \u2192</p>"},{"location":"building-blocks/langgraph/overview/","title":"LangGraph Overview","text":"<p>TL;DR: LangGraph builds stateful, cyclical workflows for LLM agents\u2014think state machines for AI.</p>"},{"location":"building-blocks/langgraph/overview/#what-is-langgraph","title":"What is LangGraph?","text":"<p>LangGraph is a framework for building stateful, multi-step workflows with LLMs. Unlike simple chains (input \u2192 LLM \u2192 output), LangGraph enables:</p> <ul> <li>Cycles: Agents can loop, retry, and refine</li> <li>State: Persistent memory across steps</li> <li>Branching: Conditional routing based on outputs</li> <li>Parallelism: Run multiple nodes concurrently</li> </ul> <p>Think of it as a state machine where each node is an AI agent or tool.</p>"},{"location":"building-blocks/langgraph/overview/#why-langgraph","title":"Why LangGraph?","text":""},{"location":"building-blocks/langgraph/overview/#the-problem-with-chains","title":"The Problem with Chains","text":"<p>Traditional LLM chains are linear:</p> <pre><code># \u274c Linear chain - can't loop or branch\nquery \u2192 retrieve_docs \u2192 generate_answer \u2192 done\n</code></pre> <p>Real agents need to: - Loop until a condition is met - Branch based on intermediate results - Maintain state across steps</p>"},{"location":"building-blocks/langgraph/overview/#the-langgraph-solution","title":"The LangGraph Solution","text":"<pre><code># \u2705 Cyclic workflow with branching\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502  generate   \u2502\n       \u2502   query     \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n              \u25bc\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502   search    \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n              \u2502              \u2502\n              \u25bc              \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n       \u2502 synthesize  \u2502      \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n              \u2502              \u2502\n              \u25bc              \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n       \u2502   check     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502  quality    \u2502 if poor, retry\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502 if good\n              \u25bc\n            END\n</code></pre>"},{"location":"building-blocks/langgraph/overview/#core-concepts","title":"Core Concepts","text":""},{"location":"building-blocks/langgraph/overview/#1-state","title":"1. State","text":"<p>State is a <code>TypedDict</code> that flows through your workflow:</p> <pre><code>from typing import TypedDict, Optional\n\nclass ResearchState(TypedDict):\n    question: str\n    search_query: Optional[str]\n    findings: Optional[str]\n    answer: Optional[str]\n</code></pre> <p>Learn more about State \u2192</p>"},{"location":"building-blocks/langgraph/overview/#2-nodes","title":"2. Nodes","text":"<p>Nodes are functions or agents that process state:</p> <pre><code>import mahsm as ma\n\n@ma.dspy_node\nclass Researcher(ma.Module):\n    def __init__(self):\n        super().__init__()\\n        self.research = dspy.ChainOfThought(\"question -&gt; findings\")\n\n    def forward(self, question):\n        return self.research(question=question)\n</code></pre> <p>Learn more about Nodes &amp; Edges \u2192</p>"},{"location":"building-blocks/langgraph/overview/#3-edges","title":"3. Edges","text":"<p>Edges connect nodes:</p> <pre><code># Simple edge\nworkflow.add_edge(\"node_a\", \"node_b\")\n\n# Conditional edge\nworkflow.add_conditional_edges(\n    \"checker\",\n    lambda state: \"retry\" if state[\"quality\"] &lt; 0.7 else END\n)\n</code></pre> <p>Learn more about Conditional Routing \u2192</p>"},{"location":"building-blocks/langgraph/overview/#4-graph-compilation","title":"4. Graph Compilation","text":"<p>Compile the workflow into an executable graph:</p> <pre><code>workflow = ma.graph.StateGraph(MyState)\nworkflow.add_node(\"agent\", my_agent)\nworkflow.add_edge(ma.START, \"agent\")\nworkflow.add_edge(\"agent\", ma.END)\n\ngraph = workflow.compile()  # \u2705 Ready to run\n</code></pre> <p>Learn more about Compilation \u2192</p>"},{"location":"building-blocks/langgraph/overview/#quick-example","title":"Quick Example","text":"<p>Let's build a self-correcting Q&amp;A agent:</p> <pre><code>import mahsm as ma\nfrom typing import TypedDict, Optional\nimport dspy\nimport os\n\n# Configure\nlm = dspy.LM('openai/gpt-4o-mini', api_key=os.getenv(\"OPENAI_API_KEY\"))\ndspy.configure(lm=lm)\nma.tracing.init()\n\n# 1. Define state\nclass QAState(TypedDict):\n    question: str\n    answer: Optional[str]\n    quality_score: Optional[float]\n    iteration: int\n\n# 2. Define nodes\n@ma.dspy_node\nclass Answerer(ma.Module):\n    def __init__(self):\n        super().__init__()\n        self.qa = dspy.ChainOfThought(\"question -&gt; answer\")\n\n    def forward(self, question):\n        return self.qa(question=question)\n\n@ma.dspy_node\nclass QualityChecker(ma.Module):\n    def __init__(self):\n        super().__init__()\n        self.checker = dspy.Predict(\"question, answer -&gt; quality_score: float 0-1\")\n\n    def forward(self, question, answer):\n        return self.checker(question=question, answer=answer)\n\ndef increment_iteration(state: QAState) -&gt; QAState:\n    \"\"\"Increment iteration counter.\"\"\"\n    return {\"iteration\": state.get(\"iteration\", 0) + 1}\n\n# 3. Define routing\ndef should_retry(state: QAState):\n    \"\"\"Retry if quality is low and we haven't exceeded max iterations.\"\"\"\n    if state.get(\"iteration\", 0) &gt;= 3:\n        return ma.END  # Give up after 3 tries\n\n    quality = float(state.get(\"quality_score\", 0))\n    if quality &lt; 0.7:\n        return \"answer\"  # Retry\n    return ma.END  # Good enough!\n\n# 4. Build graph\nworkflow = ma.graph.StateGraph(QAState)\n\nworkflow.add_node(\"answer\", Answerer())\nworkflow.add_node(\"check\", QualityChecker())\nworkflow.add_node(\"increment\", increment_iteration)\n\nworkflow.add_edge(ma.START, \"increment\")\nworkflow.add_edge(\"increment\", \"answer\")\nworkflow.add_edge(\"answer\", \"check\")\nworkflow.add_conditional_edges(\"check\", should_retry)\n\ngraph = workflow.compile()\n\n# 5. Run\nresult = graph.invoke({\n    \"question\": \"Explain quantum entanglement simply.\",\n    \"iteration\": 0\n})\n\nprint(f\"Answer: {result['answer']}\")\nprint(f\"Quality: {result['quality_score']}\")\nprint(f\"Iterations: {result['iteration']}\")\n# \u2705 Agent retries until quality threshold is met!\n</code></pre>"},{"location":"building-blocks/langgraph/overview/#langgraph-in-mahsm","title":"LangGraph in mahsm","text":"<p>mahsm enhances LangGraph with:</p>"},{"location":"building-blocks/langgraph/overview/#1-simplified-node-creation","title":"1. Simplified Node Creation","text":"<pre><code># Without mahsm\ndef my_node(state):\n    # Manual state extraction\n    question = state[\"question\"]\n    # Call LLM\n    response = llm.complete(question)\n    # Manual state update\n    return {\"answer\": response}\n\n# With mahsm\n@ma.dspy_node\nclass MyNode(ma.Module):\n    def __init__(self):\n        super().__init__()\n        self.qa = dspy.ChainOfThought(\"question -&gt; answer\")\n\n    def forward(self, question):\n        return self.qa(question=question)\n# \u2705 State extraction/merging handled automatically\n</code></pre>"},{"location":"building-blocks/langgraph/overview/#2-automatic-tracing","title":"2. Automatic Tracing","text":"<pre><code>ma.tracing.init()  # One line\n# \u2705 All LangGraph nodes traced to Langfuse\n# \u2705 All DSPy calls traced\n# \u2705 Custom functions with @observe traced\n</code></pre>"},{"location":"building-blocks/langgraph/overview/#3-type-safe-state","title":"3. Type-Safe State","text":"<pre><code>class MyState(TypedDict):\n    question: str\n    answer: str\n\n# \u2705 IDE autocomplete\n# \u2705 Static type checking\n# \u2705 Runtime validation\n</code></pre>"},{"location":"building-blocks/langgraph/overview/#when-to-use-langgraph","title":"When to Use LangGraph","text":""},{"location":"building-blocks/langgraph/overview/#great-for","title":"\u2705 Great For:","text":"<ul> <li>Multi-step agents that need memory</li> <li>Cyclical workflows (retry, refine, iterate)</li> <li>Conditional branching based on outputs</li> <li>Complex orchestration of multiple agents</li> <li>Human-in-the-loop systems</li> </ul>"},{"location":"building-blocks/langgraph/overview/#not-ideal-for","title":"\u274c Not Ideal For:","text":"<ul> <li>Simple one-shot completions (use DSPy directly)</li> <li>Purely stateless operations (no need for state management)</li> <li>Real-time streaming (LangGraph is batch-oriented)</li> </ul>"},{"location":"building-blocks/langgraph/overview/#common-patterns","title":"Common Patterns","text":""},{"location":"building-blocks/langgraph/overview/#1-linear-pipeline","title":"1. Linear Pipeline","text":"<pre><code>START \u2192 agent1 \u2192 agent2 \u2192 agent3 \u2192 END\n</code></pre> <pre><code>workflow.add_edge(ma.START, \"agent1\")\nworkflow.add_edge(\"agent1\", \"agent2\")\nworkflow.add_edge(\"agent2\", \"agent3\")\nworkflow.add_edge(\"agent3\", ma.END)\n</code></pre>"},{"location":"building-blocks/langgraph/overview/#2-conditional-branching","title":"2. Conditional Branching","text":"<pre><code>                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      START \u2500\u2500\u2500\u2500\u2500\u25ba\u2502 router  \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u25bc                 \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502 path_a \u2502       \u2502 path_b \u2502\n         \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u25bc\n                    END\n</code></pre> <pre><code>workflow.add_conditional_edges(\n    \"router\",\n    lambda state: \"path_a\" if condition(state) else \"path_b\"\n)\n</code></pre>"},{"location":"building-blocks/langgraph/overview/#3-retry-loop","title":"3. Retry Loop","text":"<pre><code>        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502              \u2502\n        \u25bc              \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  try  \u2502\u2500\u2500\u2500\u25ba\u2502   check   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u25bc\n                    END (if success)\n</code></pre> <pre><code>workflow.add_conditional_edges(\n    \"check\",\n    lambda state: \"try\" if not success(state) else ma.END\n)\n</code></pre>"},{"location":"building-blocks/langgraph/overview/#4-multi-agent-collaboration","title":"4. Multi-Agent Collaboration","text":"<pre><code>        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u250c\u2500\u2500\u25ba\u2502 researcher\u2502\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n    \u2502                     \u25bc\n    \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2514\u2500\u2500\u2500\u2502coordinator\u2502\u25c4\u2500\u2500\u2502synthesizer\u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"building-blocks/langgraph/overview/#best-practices","title":"Best Practices","text":""},{"location":"building-blocks/langgraph/overview/#do","title":"\u2705 Do:","text":"<ol> <li> <p>Use TypedDict for state <pre><code>class State(TypedDict):\n    field: str\n</code></pre></p> </li> <li> <p>Keep nodes focused <pre><code># \u2705 Single responsibility\n@ma.dspy_node\nclass QueryGenerator(ma.Module):\n    # Only generates queries\n    pass\n</code></pre></p> </li> <li> <p>Handle missing state gracefully <pre><code>def my_router(state):\n    value = state.get(\"key\", default_value)\n    # ...\n</code></pre></p> </li> <li> <p>Use conditional edges for routing <pre><code>workflow.add_conditional_edges(\"checker\", route_function)\n</code></pre></p> </li> </ol>"},{"location":"building-blocks/langgraph/overview/#dont","title":"\u274c Don't:","text":"<ol> <li> <p>Mutate state directly <pre><code># \u274c Don't do this\ndef node(state):\n    state[\"key\"] = \"value\"  # Mutates input!\n    return state\n\n# \u2705 Do this\ndef node(state):\n    return {\"key\": \"value\"}  # Returns update\n</code></pre></p> </li> <li> <p>Create infinite loops without exit conditions <pre><code># \u274c No way to exit\nworkflow.add_conditional_edges(\"node\", lambda s: \"node\")\n\n# \u2705 Add exit condition\ndef router(state):\n    if state[\"count\"] &gt; 10:\n        return ma.END\n    return \"node\"\n</code></pre></p> </li> <li> <p>Over-complicate the graph <pre><code># \u274c Too many branches\n# Keep it simple and readable\n</code></pre></p> </li> </ol>"},{"location":"building-blocks/langgraph/overview/#next-steps","title":"Next Steps","text":"<ul> <li>State Management \u2192 Learn about TypedDict and state updates</li> <li>Nodes &amp; Edges \u2192 Build your graph components</li> <li>Conditional Routing \u2192 Add branching logic</li> <li>Compilation &amp; Execution \u2192 Run your workflows</li> <li>Visualization \u2192 Visualize your graphs</li> </ul>"},{"location":"building-blocks/langgraph/overview/#external-resources","title":"External Resources","text":"<ul> <li>Official LangGraph Docs - Comprehensive guide</li> <li>LangGraph GitHub - Source code and examples</li> <li>LangGraph Tutorials - Step-by-step guides</li> </ul> <p>Ready to dive deeper? Start with State Management \u2192</p>"},{"location":"concepts/declarative-design/","title":"Declarative by Design","text":"<p>The central philosophy of <code>mahsm</code> is its declarative approach. Instead of manually writing imperative \"glue code\" to connect different libraries, you declare the components of your system, and <code>mahsm</code> handles the integration and boilerplate.</p> <p>This \"convention over configuration\" approach is designed to let you focus entirely on your agent's business logic, not the plumbing.</p>"},{"location":"concepts/declarative-design/#the-mahsm-approach","title":"The <code>mahsm</code> Approach","text":"<ul> <li>You declare your agent's reasoning by writing standard <code>dspy.Module</code> classes. The powerful <code>@ma.dspy_node</code> decorator instantly makes them compatible with the orchestration layer.</li> <li>You declare your workflow's structure by adding your nodes to a <code>ma.graph.StateGraph</code> and defining the edges between them.</li> <li>You declare your evaluation criteria by configuring the <code>ma.testing.PytestHarness</code> to run your graph against a dataset.</li> </ul>"},{"location":"concepts/declarative-design/#the-benefits","title":"The Benefits","text":"<p>This philosophy drastically reduces boilerplate, improves code readability, and embeds best practices for observability and testing directly into the development process. The result is a workflow that is faster, more robust, and produces systems that are understandable by default.</p>"},{"location":"concepts/four-pillars/","title":"The Four Pillars of <code>mahsm</code>","text":"<p><code>mahsm</code> achieves its power by deeply integrating four essential, best-in-class libraries into a single, seamless experience. All functionality is exposed through the unified <code>import mahsm as ma</code> API, giving you a consistent and clean developer experience.</p>"},{"location":"concepts/four-pillars/#1-dspy-the-reasoning-engine-madspy","title":"1. DSPy: The Reasoning Engine (<code>ma.dspy</code>)","text":"<ul> <li>What it is: A framework from Stanford NLP for programming\u2014not just prompting\u2014language models. It separates program flow from parameters (prompts and model weights) and uses optimizers to tune them for maximum performance.</li> <li>How <code>mahsm</code> Fuses it: <code>mahsm</code> treats DSPy modules as the fundamental building blocks of agent intelligence. The core innovation is the <code>@ma.dspy_node</code> decorator. This tool instantly transforms any <code>dspy.Module</code> into a fully compliant LangGraph node, automatically handling the complex mapping of data from the shared graph <code>State</code> to the module's inputs and back.</li> </ul>"},{"location":"concepts/four-pillars/#2-langgraph-the-orchestration-scaffolding-magraph","title":"2. LangGraph: The Orchestration Scaffolding (<code>ma.graph</code>)","text":"<ul> <li>What it is: A library for building stateful, multi-agent applications by representing them as cyclical graphs. It provides the primitives of <code>State</code>, <code>Nodes</code>, and <code>Edges</code> to create complex, long-running agentic workflows.</li> <li>How <code>mahsm</code> Fuses it: LangGraph provides the skeleton, and <code>mahsm</code> provides the intelligent organs. By making DSPy modules the primary type of \"thinking\" node, <code>mahsm</code> supercharges LangGraph development. You define your application's <code>State</code> and use <code>ma.graph.StateGraph</code> to wire together your <code>@ma.dspy_node</code> agents.</li> </ul>"},{"location":"concepts/four-pillars/#3-langfuse-the-unified-observability-layer","title":"3. LangFuse: The Unified Observability Layer","text":"<ul> <li>What it is: A comprehensive open-source platform for LLM observability, providing detailed tracing, debugging, and analytics for AI applications.</li> <li>How <code>mahsm</code> Fuses it: <code>mahsm</code> makes deep, hierarchical tracing an automatic, zero-effort feature. The single <code>ma.init()</code> function simultaneously instruments both LangGraph and DSPy. When you run your graph, <code>mahsm</code> creates a single, unified trace in LangFuse that captures both the high-level graph flow and the low-level DSPy execution details (prompts, tool calls, etc.), solving the massive pain point of achieving end-to-end observability.</li> </ul>"},{"location":"concepts/four-pillars/#4-evalprotocol-the-quality-control-testing-framework-matesting","title":"4. EvalProtocol: The Quality Control &amp; Testing Framework (<code>ma.testing</code>)","text":"<ul> <li>What it is: A standardized, <code>pytest</code>-based framework for evaluating the performance of AI systems using LLM-as-a-judge and other metrics.</li> <li>How <code>mahsm</code> Fuses it: <code>mahsm</code> bridges the gap between your built application and your test suite. The <code>ma.testing.PytestHarness</code> class radically simplifies setup by automatically generating the boilerplate processors required by <code>eval-protocol</code>. The harness can even pull evaluation datasets directly from your production LangFuse traces, enabling a tight, continuous loop of deploying, observing, and evaluating your system's real-world performance.</li> </ul>"},{"location":"concepts/workflow/","title":"The <code>mahsm</code> Development Workflow","text":"<p>Developing with <code>mahsm</code> follows a simple, iterative, and powerful three-step loop: Build, Trace, and Evaluate. This cycle is designed to be fast and data-driven, ensuring you are creating high-quality, robust systems.</p> <p> </p>"},{"location":"concepts/workflow/#1-build","title":"1. Build","text":"<p>This is the core development step where you write idiomatic <code>mahsm</code> code. - Define State: Create a <code>TypedDict</code> that represents the shared state of your application. - Create Nodes: Write <code>dspy.Module</code> classes to encapsulate the reasoning logic for your agents. Decorate them with <code>@ma.dspy_node</code>. - Wire Graph: Add your nodes to a <code>ma.graph.StateGraph</code> and define the edges to control the flow of execution. - Compile: Call <code>.compile()</code> on your graph to create the runnable application.</p>"},{"location":"concepts/workflow/#2-trace","title":"2. Trace","text":"<p>Once built, you run your application.     *   With <code>ma.init()</code> called at the start of your script, every execution is automatically and deeply traced in LangFuse.     *   You use the LangFuse UI to inspect the full decision-making process of your agent, debug issues, understand latency, and analyze token usage.     *   You can tag interesting traces to save them as examples for regression testing or for creating evaluation datasets.</p>"},{"location":"concepts/workflow/#3-evaluate","title":"3. Evaluate","text":"<p>Finally, you verify the quality of your agent's output.     *   Write a Test File: Create a standard <code>pytest</code> file.     *   Configure the Harness: Use the <code>ma.testing.PytestHarness</code> to connect your compiled <code>mahsm</code> graph to the evaluation protocol.     *   Run Eval: Use datasets (potentially generated from your production traces in LangFuse) to run an evaluation.     *   Analyze &amp; Iterate: Use the evaluation leaderboards and results to identify weaknesses in your agent's logic, then go back to the BUILD step to improve it.</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Getting <code>mahsm</code> installed is quick and easy. We recommend using a virtual environment to manage your project's dependencies.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li><code>uv</code> (or <code>pip</code>) package installer</li> </ul>"},{"location":"getting-started/installation/#installing-mahsm","title":"Installing <code>mahsm</code>","text":"<p>To install the core <code>mahsm</code> library, run the following command:</p> <pre><code>uv pip install mahsm\n</code></pre> <p>This will install mahsm and its core dependencies, including DSPy, LangGraph, LangFuse, and EvalProtocol.</p>"},{"location":"getting-started/installation/#setting-up-observability-langfuse","title":"Setting Up Observability (LangFuse)","text":"<p>One of the core features of mahsm is its deep integration with LangFuse for observability. To enable it, you need to set the following environment variables: <pre><code>export LANGFUSE_PUBLIC_KEY=\"pk-lf-...\"\nexport LANGFUSE_SECRET_KEY=\"sk-lf-...\"\nexport LANGFUSE_HOST=\"https://cloud.langfuse.com\" # Or your self-hosted instance\n</code></pre></p> <p>You can find your keys in your LangFuse project settings.</p>"},{"location":"getting-started/quickstart/","title":"Quickstart: Building Your First <code>mahsm</code> Agent","text":"<p>Let's build a simple research agent to see how the core components of <code>mahsm</code> work together. This example demonstrates the declarative nature of the framework.</p>"},{"location":"getting-started/quickstart/#1-the-single-import","title":"1. The Single Import","text":"<p>All of <code>mahsm</code>'s fused functionality is available through the top-level <code>ma</code> import.</p> <pre><code>import mahsm as ma\nfrom typing import TypedDict, Optional\n</code></pre>"},{"location":"getting-started/quickstart/#2-define-the-shared-state","title":"2. Define the Shared State","text":"<p>The State is a TypedDict that defines the data structure that flows through your graph. Every node can read from and write to this state.</p> <pre><code>class AgentState(TypedDict):\n    input_query: str\n    research_result: Optional[str]\n</code></pre>"},{"location":"getting-started/quickstart/#3-create-a-reasoning-node-with-madspy_node","title":"3. Create a Reasoning Node with @ma.dspy_node","text":"<p>Here, we define the \"brain\" of our agent using a <code>dspy.Module</code>. The <code>@ma.dspy_node</code> decorator is the magic that makes this module compatible with the LangGraph orchestrator, automatically handling data mapping from the AgentState.</p> <pre><code>@ma.dspy_node\nclass Researcher(ma.Module):\n    def __init__(self):\n        super().__init__()\n        self.signature = \"input_query -&gt; research_result\"\n        self.predictor = ma.dspy.ChainOfThought(self.signature)\n\n    def forward(self, input_query):\n        return self.predictor(input_query=input_query)\n</code></pre>"},{"location":"getting-started/quickstart/#4-build-and-compile-the-graph","title":"4. Build and Compile the Graph","text":"<p>Finally, we use <code>ma.graph.StateGraph</code> to define the workflow. We add our <code>Researcher</code> node and define the edges that control the flow of execution.</p> <pre><code># Initialize the graph with our state definition\nworkflow = ma.graph.StateGraph(AgentState)\n\n# Add the DSPy-powered node\nworkflow.add_node(\"researcher\", Researcher())\n\n# Define the workflow structure\nworkflow.add_edge(ma.START, \"researcher\")\nworkflow.add_edge(\"researcher\", ma.END)\n\n# Compile the graph into a runnable application\ngraph = workflow.compile()\n</code></pre>"},{"location":"getting-started/quickstart/#5-run-and-trace","title":"5. Run and Trace","text":"<p>To run your agent, simply invoke the graph. If you've called ma.init() beforehand, the entire execution will be traced in LangFuse automatically.</p> <pre><code># Initialize tracing (do this once at the start of your app)\nma.init()\n\n# Run the graph\ninputs = {\"input_query\": \"What is the future of multi-agent AI systems?\"}\nresult = graph.invoke(inputs)\n\nprint(result['research_result'])\n</code></pre> <p>That's it! You've built a fully observable and testable agent with minimal boilerplate, focusing only on the essential logic.</p>"}]}